{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MasuFl9xu-er"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import random\n",
        "import torchvision\n",
        "import itertools\n",
        "import numpy as np\n",
        "from IPython.display import clear_output\n",
        "import torch.nn as nn\n",
        "import seaborn as sns\n",
        "from einops import rearrange\n",
        "from tqdm import tqdm\n",
        "from random import Random\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.transforms import Resize, ToTensor\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torchvision.transforms.functional import to_pil_image\n",
        "from sklearn.metrics import confusion_matrix, classification_report,accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Batch_size = 12"
      ],
      "metadata": {
        "id": "heqQm9xz10iM"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# DATASET"
      ],
      "metadata": {
        "id": "fNR_nx2kZL5u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
        "])\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "Actual_train_dataset = torchvision.datasets.MNIST(root='./data',train=True,download = True,transform = transform)\n",
        "Actual_test_dataset = torchvision.datasets.MNIST(root='./data',train = False,download = True,transform = transform)"
      ],
      "metadata": {
        "id": "H4YS7t0cvKcn"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes_to_sample = [0,1,2]"
      ],
      "metadata": {
        "id": "I1lVsE1EvZt8"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples = []\n",
        "previous_train_indices = []\n",
        "for cls in classes_to_sample:\n",
        "  class_indices = [i for i,label in enumerate(Actual_train_dataset.targets) if label == cls]\n",
        "  sampled_indices = np.random.choice(class_indices,100,replace = False)\n",
        "  previous_train_indices.append(sampled_indices)\n",
        "  # print(sampled_indices)\n",
        "  sampled_images = torch.stack([Actual_train_dataset[i][0] for i in sampled_indices])\n",
        "  train_samples.append(sampled_images)\n",
        "\n",
        "train_samples = torch.cat(train_samples,dim=0)\n",
        "# print(previous_train_indices)\n"
      ],
      "metadata": {
        "id": "5TU-KP57vdFM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_samples=[]\n",
        "previous_test_indices=[]\n",
        "for cls in classes_to_sample:\n",
        "  class_indices = [i for i,label in enumerate(Actual_test_dataset.targets) if label == cls]\n",
        "  sampled_indices = np.random.choice(class_indices,100, replace = False)\n",
        "  previous_test_indices.append(sampled_indices)\n",
        "  sampled_images = torch.stack([Actual_test_dataset[i][0] for i in sampled_indices])\n",
        "  test_samples.append(sampled_images)\n",
        "\n",
        "test_samples = torch.cat(test_samples,dim=0)\n",
        "print(len(test_samples))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2EG8-nCbvv0v",
        "outputId": "82455422-196e-4a8f-da66-1b6a3bea3795"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "300\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the datasets to pytorch TensorDatasets"
      ],
      "metadata": {
        "id": "ELvgsuNWwPRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_labels = torch.cat([torch.full((100,),i) for i in [0,1,2]])\n",
        "test_labels = torch.cat([torch.full((100,),i) for i in [0,1,2]])\n",
        "\n",
        "train_dataset = TensorDataset(train_samples,train_labels)\n",
        "test_dataset = TensorDataset(test_samples,test_labels)"
      ],
      "metadata": {
        "id": "4i_q_T2lvz_S"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(train_dataset,batch_size=Batch_size,shuffle=True)\n",
        "test_loader = DataLoader(test_dataset,batch_size=Batch_size,shuffle=False)"
      ],
      "metadata": {
        "id": "6aytkDInwWqO"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 a\n",
        "VIT Blocks"
      ],
      "metadata": {
        "id": "DvDpXr84AbXt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_size = 28  # MNIST images are 28x28\n",
        "patch_size = 7  # As per the question\n",
        "num_patches = (img_size // patch_size) ** 2  # Should be 16 for 28x28 images with 7x7 patches\n",
        "embed_dim = 128  # As per the question\n",
        "num_heads = 8\n",
        "depth = 2\n",
        "mlp_dim = 256\n",
        "learning_rate = 0.001"
      ],
      "metadata": {
        "id": "aRJJDU_AAveq"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding_conv(nn.Module):\n",
        "  def __init__(self,img_size,patch_size,in_channels=1,embed_dim=128):\n",
        "    super(PatchEmbedding_conv,self).__init__()\n",
        "    self.patch_size = patch_size\n",
        "    self.proj = nn.Conv2d(in_channels,embed_dim,kernel_size=patch_size,stride=patch_size)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.proj(x)\n",
        "    x=rearrange(x,'b e h w -> b (h w) e')\n",
        "    return x\n",
        "\n",
        "patch_embedding = PatchEmbedding_conv(img_size,patch_size)\n",
        "sample_image = next(iter(train_loader))[0][0].unsqueeze(0)\n",
        "# sample_image = torch.randn(12,1,28,28)\n",
        "# print(sample_image.shape)\n",
        "patches = patch_embedding(sample_image)\n",
        "print(patches.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DQJO4mqRwZHm",
        "outputId": "34e1a718-3b50-4e37-9900-1b64708c16f8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MASKING"
      ],
      "metadata": {
        "id": "n9HGWH14ZXdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import pathconf_names\n",
        "def mask_tokens(x, mask_ratio=0.5):\n",
        "    \"\"\"\n",
        "    x: Tensor of shape (batch_size, num_patches, embed_dim)\n",
        "    mask_ratio: The ratio of tokens to mask\n",
        "    Returns:\n",
        "        masked_x: Tensor with masked tokens replaced by zeros\n",
        "        mask: Boolean mask indicating which tokens are masked\n",
        "    \"\"\"\n",
        "    batch_size, num_patches, embed_dim = x.shape\n",
        "    num_masked = int(num_patches * mask_ratio)\n",
        "    mask = torch.zeros(batch_size, num_patches, dtype=torch.bool)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        masked_indices = random.sample(range(num_patches), num_masked)\n",
        "        mask[i, masked_indices] = True\n",
        "\n",
        "    masked_x = x.clone()\n",
        "    masked_x[mask.unsqueeze(-1).expand_as(x)] = 0\n",
        "    return masked_x, mask\n",
        "\n",
        "x,y = mask_tokens(patches)"
      ],
      "metadata": {
        "id": "jNZbx75e2YRw"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MultiHead Self Attention"
      ],
      "metadata": {
        "id": "NJ9Dlp8BpZhh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadSelfAttention(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads):\n",
        "        super(MultiHeadSelfAttention, self).__init__()\n",
        "        assert embed_dim % num_heads == 0, \"Embedding dimension must be divisible by the number of heads.\"\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        self.query = nn.Linear(embed_dim, embed_dim)\n",
        "        self.key = nn.Linear(embed_dim, embed_dim)\n",
        "        self.value = nn.Linear(embed_dim, embed_dim)\n",
        "        self.out = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.shape)\n",
        "        B, N, C = x.shape\n",
        "        q = self.query(x).view(B, N, self.num_heads, self.head_dim)\n",
        "        k = self.key(x).view(B, N, self.num_heads, self.head_dim)\n",
        "        v = self.value(x).view(B, N, self.num_heads, self.head_dim)\n",
        "\n",
        "        q, k, v = map(lambda t: rearrange(t, 'b n h d -> b h n d'), (q, k, v))\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * (self.head_dim ** -0.5)\n",
        "\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        # print(attn.shape)\n",
        "        out = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        out = self.out(out)\n",
        "        return out,attn\n",
        "\n",
        "# Test Multi-Head Self-Attention\n",
        "mhsa = MultiHeadSelfAttention(embed_dim=128, num_heads=8)\n",
        "attn_output,attn = mhsa(patches)\n",
        "# print(attn.shape)\n",
        "print(attn_output.shape)  # Expected shape: (1, num_patches, embed_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gDa9f7xwgkA",
        "outputId": "bcd9f47c-9c12-46c1-cc0f-e9d991347c70"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder Block"
      ],
      "metadata": {
        "id": "tG3zj6Xypd20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Module):\n",
        "    def __init__(self, embed_dim, num_heads, mlp_dim, dropout=0):\n",
        "        super(TransformerEncoderBlock, self).__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.mhsa = MultiHeadSelfAttention(embed_dim, num_heads)\n",
        "        self.dropout1 = nn.Dropout(dropout)\n",
        "\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(embed_dim, mlp_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_dim, embed_dim),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "        self.dropout2 = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attn_out,attn=self.mhsa(x)\n",
        "        x = x + self.dropout1(attn_out)\n",
        "        x = x + self.norm2(self.mlp(self.norm1(x)))\n",
        "        return x\n",
        "\n",
        "# Test Transformer Encoder Block\n",
        "encoder_block = TransformerEncoderBlock(embed_dim=128, num_heads=8, mlp_dim=256)\n",
        "encoded_output = encoder_block(attn_output)\n",
        "print(encoded_output.shape)  # Expected shape: (1, num_patches, embed_dim)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gje28s_KAcJ1",
        "outputId": "55c3a60a-6737-47da-e0e0-eadd9377fa5b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 16, 128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "VIT by using MAE loss function."
      ],
      "metadata": {
        "id": "Bh31Htr9pgr3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerMAE(nn.Module):\n",
        "    def __init__(self, img_size=28, patch_size=7, embed_dim=128, depth=2, num_heads=8, mlp_dim=256, dropout=0.1):\n",
        "        super(VisionTransformerMAE, self).__init__()\n",
        "        self.patch_embedding = PatchEmbedding_conv(img_size, patch_size, in_channels=1, embed_dim=embed_dim)\n",
        "        num_patches = (img_size // patch_size) ** 2  # Should be 16 for 28x28 images with 7x7 patches\n",
        "\n",
        "        # Positional embedding without class token\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches, embed_dim))\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        # Prediction head for reconstructing the masked patches\n",
        "        self.prediction_head = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward_encoder(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass through the encoder.\n",
        "        x: Input tensor of shape (batch_size, num_patches, embed_dim)\n",
        "        \"\"\"\n",
        "        x = self.dropout(x)\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Apply the prediction head to all tokens\n",
        "        x = self.prediction_head(self.forward_encoder(x))\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "mJuVI7OYLxVf"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAE Loss function"
      ],
      "metadata": {
        "id": "Dqrx_FD5pl8P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_mae_loss(predictions, targets, mask):\n",
        "    \"\"\"\n",
        "    predictions: Tensor of shape (batch_size, num_patches, embed_dim)\n",
        "    targets: Tensor of shape (batch_size, num_patches, embed_dim)\n",
        "    mask: Boolean mask indicating which tokens were masked\n",
        "    \"\"\"\n",
        "    loss_fn = nn.MSELoss()\n",
        "    # Only compute loss on masked tokens\n",
        "    # print(mask.unsqueeze(-1).expand_as(predictions))\n",
        "    masked_predictions = predictions[mask.unsqueeze(-1).expand_as(predictions)]\n",
        "    masked_targets = targets[mask.unsqueeze(-1).expand_as(targets)]\n",
        "    loss = loss_fn(masked_predictions, masked_targets)\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "LFfg1rDmL5CZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot to see whether it is masking the 50% of the patches or not"
      ],
      "metadata": {
        "id": "_zed9A1jouHA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# def plot_tensor_image(tensor, index=0):\n",
        "#     \"\"\"\n",
        "#     Plots a single image from a tensor with shape (batch_size, height, width).\n",
        "\n",
        "#     Args:\n",
        "#         tensor (torch.Tensor): Input tensor of shape (batch_size, height, width).\n",
        "#         index (int): Index of the image in the batch to plot.\n",
        "#     \"\"\"\n",
        "#     # Ensure the tensor is on the CPU and detach if necessary\n",
        "#     tensor = tensor.cpu().detach()\n",
        "\n",
        "#     # Select the image at the specified index\n",
        "#     image = tensor[index]\n",
        "\n",
        "#     # Plot the image (considering it as a grayscale image)\n",
        "#     plt.imshow(image, cmap='gray')\n",
        "#     plt.title(f\"Image from batch index {index}\")\n",
        "#     plt.show()\n",
        "\n",
        "# # # Example usage with a tensor of shape (12, 16, 128)\n",
        "# # tensor = torch.randn(12, 16, 128)\n",
        "# # plot_tensor_image(tensor, index=0)  # Plots the first image in the batch\n"
      ],
      "metadata": {
        "id": "UFMcfncpn9zC"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the model and optimizer"
      ],
      "metadata": {
        "id": "WT8I1Dwipq29"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model parameters\n",
        "img_size = 28\n",
        "patch_size = 7\n",
        "embed_dim = 128\n",
        "depth = 2\n",
        "num_heads = 8\n",
        "mlp_dim = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "mae_model = VisionTransformerMAE(\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_dim=mlp_dim,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(mae_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "L616yckKp1GA"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "MAE training pipeline"
      ],
      "metadata": {
        "id": "4LkZ2VAWqm2m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10 # At least 10 epochs as per the question\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    mae_model.train()\n",
        "    total_loss = 0\n",
        "    for batch in train_loader:\n",
        "        images, _ = batch\n",
        "        images = images.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Step 1: Obtain patches and add positional encoding\n",
        "        patches = mae_model.patch_embedding(images)  # Shape: (batch_size, num_patches, embed_dim)\n",
        "        # plot_tensor_image(patches, index=0)\n",
        "        patches += mae_model.pos_embedding  # Add positional encoding\n",
        "        # plot_tensor_image(patches, index=0)\n",
        "\n",
        "        # Step 2: Apply masking to patches\n",
        "        masked_patches, mask = mask_tokens(patches, mask_ratio=0.5)\n",
        "        masked_patches = masked_patches.to(device)\n",
        "        # plot_tensor_image(masked_patches, index=0)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "\n",
        "        # Step 3: Forward pass through the encoder\n",
        "        encoded_patches = mae_model.forward_encoder(masked_patches)\n",
        "\n",
        "        # Step 4: Apply the prediction head\n",
        "        predictions = mae_model.prediction_head(encoded_patches)\n",
        "\n",
        "        # Step 5: Compute the loss\n",
        "        targets = patches  # Original patches with positional encoding\n",
        "        loss = compute_mae_loss(predictions, targets, mask)\n",
        "\n",
        "        # Step 6: Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "qEzjYbFf6VzY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5d61cd89-f46e-4857-a33a-1e035e68df14"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.1966\n",
            "Epoch [2/10], Loss: 0.9900\n",
            "Epoch [3/10], Loss: 0.8969\n",
            "Epoch [4/10], Loss: 0.8267\n",
            "Epoch [5/10], Loss: 0.7688\n",
            "Epoch [6/10], Loss: 0.7224\n",
            "Epoch [7/10], Loss: 0.6844\n",
            "Epoch [8/10], Loss: 0.6519\n",
            "Epoch [9/10], Loss: 0.6245\n",
            "Epoch [10/10], Loss: 0.5984\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 a classifier\n",
        "Finetune the model for classification"
      ],
      "metadata": {
        "id": "uW4LnaNPZmhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerClassifierMeanPool(nn.Module):\n",
        "    def __init__(self, pretrained_model, num_classes=3):\n",
        "        super(VisionTransformerClassifierMeanPool, self).__init__()\n",
        "        self.encoder = pretrained_model.encoder  # Use the pretrained encoder (from MAE)\n",
        "        self.patch_embedding = pretrained_model.patch_embedding\n",
        "        self.pos_embedding = pretrained_model.pos_embedding  # Use positional embeddings from pretrained model\n",
        "        self.dropout = pretrained_model.dropout\n",
        "\n",
        "        embed_dim = pretrained_model.pos_embedding.shape[-1]\n",
        "\n",
        "        # Classification head\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)  # Output: number of classes\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Step 1: Patch Embedding\n",
        "        x = self.patch_embedding(x)  # Shape: (batch_size, num_patches, embed_dim)\n",
        "\n",
        "        # Step 2: Add Positional Encoding\n",
        "        x += self.pos_embedding  # Add positional encodings to the patches\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Step 3: Pass through transformer encoder blocks\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "\n",
        "        # Step 4: Mean Pooling (instead of CLS token)\n",
        "        x = x.mean(dim=1)  # Mean pooling over all the patch tokens\n",
        "\n",
        "        # Step 5: Pass through classification head\n",
        "        x = self.mlp_head(x)  # Shape: (batch_size, num_classes)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "GjzemzSC90LM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the classifier model"
      ],
      "metadata": {
        "id": "J__ndXTNq3pR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selected_classes = classes_to_sample\n",
        "classifier_model = VisionTransformerClassifierMeanPool(mae_model, num_classes=len(selected_classes)).to(device)\n",
        "\n",
        "# loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "whr9dmNIosv8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning pipeline"
      ],
      "metadata": {
        "id": "Nx8kn_cFq73J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_finetune_epochs = 10\n",
        "\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    classifier_model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Finetune Epoch [{epoch + 1}/{num_finetune_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSNzVuSot_0",
        "outputId": "9fc47075-812c-417e-f296-b33679acc071"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finetune Epoch [1/10], Loss: 0.7585\n",
            "Finetune Epoch [2/10], Loss: 0.2919\n",
            "Finetune Epoch [3/10], Loss: 0.1690\n",
            "Finetune Epoch [4/10], Loss: 0.0828\n",
            "Finetune Epoch [5/10], Loss: 0.1020\n",
            "Finetune Epoch [6/10], Loss: 0.1613\n",
            "Finetune Epoch [7/10], Loss: 0.1201\n",
            "Finetune Epoch [8/10], Loss: 0.0387\n",
            "Finetune Epoch [9/10], Loss: 0.0487\n",
            "Finetune Epoch [10/10], Loss: 0.0380\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on Test dataset"
      ],
      "metadata": {
        "id": "m7IzFjMCrEcD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = classifier_model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "EhdSS6Rwo9-M"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1a Accuracy and confusion Matrix\n",
        "Test Accuracy and Confusion Matrix"
      ],
      "metadata": {
        "id": "8dpOZyJXsrsZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=selected_classes, yticklabels=selected_classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "G6DYC1ImpCMG",
        "outputId": "35311567-1134-4a9a-ee19-3accb91207fc"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 98.00%\n",
            "Confusion Matrix:\n",
            "[[98  0  2]\n",
            " [ 0 98  2]\n",
            " [ 2  0 98]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 b - VIT with cls token\n"
      ],
      "metadata": {
        "id": "GsaEqVlRRm0M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerWithCLS(nn.Module):\n",
        "    def __init__(self, img_size=28, patch_size=7, embed_dim=128, depth=2, num_heads=8, mlp_dim=256, dropout=0.1):\n",
        "        super(VisionTransformerWithCLS, self).__init__()\n",
        "        self.patch_embedding = PatchEmbedding_conv(img_size, patch_size, in_channels=1, embed_dim=embed_dim)\n",
        "        num_patches = (img_size // patch_size) ** 2  # Should be 16 for 28x28 images with 7x7 patches\n",
        "\n",
        "        # Initialize class token and positional embeddings\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))  # +1 for CLS token\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Transformer encoder blocks\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)  # Shape: (batch_size, num_patches, embed_dim)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # Shape: (batch_size, 1, embed_dim)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # Now x has shape (batch_size, num_patches + 1, embed_dim)\n",
        "\n",
        "        x += self.pos_embedding\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "\n",
        "        return x  # Return all tokens including CLS token\n"
      ],
      "metadata": {
        "id": "VXFJIivARqZW"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "InfoNCE Loss"
      ],
      "metadata": {
        "id": "zVVY6feEuAr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def info_nce_loss(features, labels, temperature=0.5):\n",
        "    \"\"\"\n",
        "    Compute the InfoNCE loss for a batch of features.\n",
        "\n",
        "    features: Tensor of shape (batch_size, embed_dim)\n",
        "    labels: Tensor of shape (batch_size)\n",
        "    temperature: Temperature parameter for scaling.\n",
        "\n",
        "    Returns:\n",
        "        loss: Scalar tensor representing the loss.\n",
        "    \"\"\"\n",
        "    batch_size = features.shape[0]\n",
        "    # Normalize features\n",
        "    features = F.normalize(features, dim=1)\n",
        "\n",
        "    # Compute similarity matrix\n",
        "    similarity_matrix = torch.matmul(features, features.T)  # Shape: (batch_size, batch_size)\n",
        "    similarity_matrix = similarity_matrix / temperature\n",
        "\n",
        "    # Create labels for InfoNCE loss\n",
        "    labels = labels.contiguous().view(-1, 1)  # Shape: (batch_size, 1)\n",
        "    mask = torch.eq(labels, labels.T).float().to(features.device)  # Shape: (batch_size, batch_size)\n",
        "\n",
        "    # Remove self-similarity\n",
        "    logits_mask = torch.ones_like(mask) - torch.eye(batch_size).to(features.device)\n",
        "    mask = mask * logits_mask\n",
        "\n",
        "    # Compute log probabilities\n",
        "    exp_sim = torch.exp(similarity_matrix) * logits_mask\n",
        "    log_prob = similarity_matrix - torch.log(exp_sim.sum(dim=1, keepdim=True) + 1e-8)\n",
        "\n",
        "    # Compute mean of log-likelihood over positive samples\n",
        "    mean_log_prob_pos = (mask * log_prob).sum(dim=1) / (mask.sum(dim=1) + 1e-8)\n",
        "\n",
        "    # Loss\n",
        "    loss = -mean_log_prob_pos.mean()\n",
        "\n",
        "    return loss\n"
      ],
      "metadata": {
        "id": "-9DyCg0IRsX-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Intializing the model and parameters and optimizer"
      ],
      "metadata": {
        "id": "sgCD8AvFuEQv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model parameters\n",
        "img_size = 28\n",
        "patch_size = 7\n",
        "embed_dim = 128\n",
        "depth = 2\n",
        "num_heads = 8\n",
        "mlp_dim = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model\n",
        "vit_model = VisionTransformerWithCLS(\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_dim=mlp_dim,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "optimizer = optim.Adam(vit_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "0VdRHhhYRvAM"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training pipeline"
      ],
      "metadata": {
        "id": "H00d8feWuNx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "num_epochs = 10  # At least 10 epochs as per the question\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    vit_model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = vit_model(images)  # Shape: (batch_size, num_patches + 1, embed_dim)\n",
        "        cls_tokens = outputs[:, 0]  # Extract CLS token representations\n",
        "\n",
        "        # Compute InfoNCE loss\n",
        "        loss = info_nce_loss(cls_tokens, labels)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SrlBmSSR3s-",
        "outputId": "6a00ed6e-a192-4e23-c9e6-3ece7108e6c8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 2.1687\n",
            "Epoch [2/10], Loss: 1.8095\n",
            "Epoch [3/10], Loss: 1.6822\n",
            "Epoch [4/10], Loss: 1.5964\n",
            "Epoch [5/10], Loss: 1.6806\n",
            "Epoch [6/10], Loss: 1.8883\n",
            "Epoch [7/10], Loss: 1.6188\n",
            "Epoch [8/10], Loss: 1.4424\n",
            "Epoch [9/10], Loss: 1.4506\n",
            "Epoch [10/10], Loss: 1.4340\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning the Model for classificaiton"
      ],
      "metadata": {
        "id": "NLmSGkosuUHT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerClassifierWithCLS(nn.Module):\n",
        "    def __init__(self, pretrained_model, num_classes=3):\n",
        "        super(VisionTransformerClassifierWithCLS, self).__init__()\n",
        "        self.encoder = pretrained_model.encoder  # Use the pretrained encoder\n",
        "        self.patch_embedding = pretrained_model.patch_embedding\n",
        "        self.cls_token = pretrained_model.cls_token\n",
        "        self.pos_embedding = pretrained_model.pos_embedding\n",
        "        self.dropout = pretrained_model.dropout\n",
        "\n",
        "        # Classification head\n",
        "        embed_dim = pretrained_model.cls_token.shape[-1]\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch_embedding(x)  # Shape: (batch_size, num_patches, embed_dim)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # Shape: (batch_size, 1, embed_dim)\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # Now x has shape (batch_size, num_patches + 1, embed_dim)\n",
        "\n",
        "        x += self.pos_embedding\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "\n",
        "        # Classification is based on the class token\n",
        "        x = self.mlp_head(x[:, 0])  # Use the class token representation\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "v26yh4HER7B0"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the classifier model"
      ],
      "metadata": {
        "id": "WxcQ8t8JuYuT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model = VisionTransformerClassifierWithCLS(vit_model, num_classes=len(selected_classes)).to(device)\n",
        "\n",
        "# Define the optimizer and loss function\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(classifier_model.parameters(), lr=learning_rate)\n"
      ],
      "metadata": {
        "id": "SFiMMzbJR-YJ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetuning pipeline"
      ],
      "metadata": {
        "id": "kTUQmgNwuczG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_finetune_epochs = 10  # You can adjust this\n",
        "\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    classifier_model.train()\n",
        "    total_loss = 0\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = classifier_model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Finetune Epoch [{epoch + 1}/{num_finetune_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OamfZV_MSBSH",
        "outputId": "08bd35fd-3a9c-4eca-e217-6eec1f9166f3"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Finetune Epoch [1/10], Loss: 0.2100\n",
            "Finetune Epoch [2/10], Loss: 0.1551\n",
            "Finetune Epoch [3/10], Loss: 0.0582\n",
            "Finetune Epoch [4/10], Loss: 0.0506\n",
            "Finetune Epoch [5/10], Loss: 0.0696\n",
            "Finetune Epoch [6/10], Loss: 0.0540\n",
            "Finetune Epoch [7/10], Loss: 0.0415\n",
            "Finetune Epoch [8/10], Loss: 0.0203\n",
            "Finetune Epoch [9/10], Loss: 0.0172\n",
            "Finetune Epoch [10/10], Loss: 0.0196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating the model on the test dataset"
      ],
      "metadata": {
        "id": "Y8pTdf-juhwW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = classifier_model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n"
      ],
      "metadata": {
        "id": "Jp3hF_x8SDLk"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1b Accuracy and Confusion Matrix\n",
        "Test accuracy and confusion matrix"
      ],
      "metadata": {
        "id": "EhSIXoFnupwo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=selected_classes, yticklabels=selected_classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "8bkkxinuSISn",
        "outputId": "763b8475-cba3-42b3-8b61-b2f2603efe6b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.33%\n",
            "Confusion Matrix:\n",
            "[[ 96   0   4]\n",
            " [  0 100   0]\n",
            " [  2   2  96]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 c VIT with MAE and InfoNCE"
      ],
      "metadata": {
        "id": "Rn0oEQvcQkdA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerMAEInfoNCE(nn.Module):\n",
        "    def __init__(self, img_size=28, patch_size=7, embed_dim=128, depth=2, num_heads=8, mlp_dim=256, dropout=0.1):\n",
        "        super(VisionTransformerMAEInfoNCE, self).__init__()\n",
        "        self.patch_embedding = PatchEmbedding_conv(img_size, patch_size, in_channels=1, embed_dim=embed_dim)\n",
        "        num_patches = (img_size // patch_size) ** 2  # Should be 16 for 28x28 images with 7x7 patches\n",
        "\n",
        "        # Initialize CLS token and positional embeddings\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, embed_dim))\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches + 1, embed_dim))  # +1 for CLS token\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "        # Transformer encoder\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "        # MAE reconstruction head\n",
        "        self.prediction_head = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x, mask=None):\n",
        "        # Patch Embedding\n",
        "        x = self.patch_embedding(x)  # Shape: (batch_size, num_patches, embed_dim)\n",
        "\n",
        "        batch_size = x.shape[0]\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)  # Shape: (batch_size, 1, embed_dim)\n",
        "\n",
        "        # Append CLS token\n",
        "        x = torch.cat((cls_tokens, x), dim=1)  # Now x has shape (batch_size, num_patches + 1, embed_dim)\n",
        "\n",
        "        # Add positional embeddings\n",
        "        x += self.pos_embedding\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through transformer encoder\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "\n",
        "        # Separate CLS token and patch tokens\n",
        "        cls_token = x[:, 0]  # CLS token\n",
        "        patch_tokens = x[:, 1:]  # Patch tokens\n",
        "\n",
        "        if mask is not None:\n",
        "            # Return predicted patch embeddings for MAE\n",
        "            return cls_token, self.prediction_head(patch_tokens)\n",
        "\n",
        "        # If no mask, just return CLS token and patch tokens\n",
        "        return cls_token, patch_tokens\n"
      ],
      "metadata": {
        "id": "t7aOZg1CkjWU"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Combined Loss"
      ],
      "metadata": {
        "id": "iYgfMROBoinY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combined_loss(cls_token, patches, predictions, targets, mask, labels, mae_weight=0.8, info_nce_weight=0.2):\n",
        "    # Compute MAE loss (only on masked patches)\n",
        "    mae_loss = compute_mae_loss(predictions, targets, mask)\n",
        "\n",
        "    # Compute InfoNCE loss (on CLS token)\n",
        "    info_nce_loss_value = info_nce_loss(cls_token, labels)\n",
        "\n",
        "    # Combine the two losses with specified weights\n",
        "    return mae_weight * mae_loss + info_nce_weight * info_nce_loss_value\n",
        "\n"
      ],
      "metadata": {
        "id": "zgQEkaf_Q1Ue"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initilizing Model , parameters and optimizer"
      ],
      "metadata": {
        "id": "qY-NjeiNoqqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Model parameters\n",
        "img_size = 28\n",
        "patch_size = 7\n",
        "embed_dim = 128\n",
        "depth = 2\n",
        "num_heads = 8\n",
        "mlp_dim = 256\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Initialize the model\n",
        "MAEInfoNCE_model = VisionTransformerMAEInfoNCE(\n",
        "    img_size=img_size,\n",
        "    patch_size=patch_size,\n",
        "    embed_dim=embed_dim,\n",
        "    depth=depth,\n",
        "    num_heads=num_heads,\n",
        "    mlp_dim=mlp_dim,\n",
        "    dropout=0.1\n",
        ").to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(MAEInfoNCE_model.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "cA9OcsPZopKs"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training Pipeline"
      ],
      "metadata": {
        "id": "hV8tr4HYw9aw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Training loop\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    MAEInfoNCE_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Obtain patches and add positional encoding\n",
        "        patches = MAEInfoNCE_model.patch_embedding(images)\n",
        "        patches += MAEInfoNCE_model.pos_embedding[:, 1:]  # Ignore the CLS token for patch embeddings\n",
        "\n",
        "        # Mask tokens for MAE\n",
        "        masked_patches, mask = mask_tokens(patches, mask_ratio=0.5)\n",
        "        masked_patches = masked_patches.to(device)\n",
        "        mask = mask.to(device)\n",
        "\n",
        "        # Forward pass through the model\n",
        "        cls_token, recon_patches = MAEInfoNCE_model(images, mask=mask)\n",
        "\n",
        "        # Compute the combined loss (MAE + InfoNCE)\n",
        "        mae_target = patches  # The original, unmasked patches\n",
        "        loss = combined_loss(cls_token, patches, recon_patches, mae_target, mask, labels)\n",
        "\n",
        "        # Backpropagation and optimization\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "id": "aXZp1oDkQ2QN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5830dad7-cfc0-4d08-d3e3-ac7979a469b5"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.0473\n",
            "Epoch [2/10], Loss: 0.6121\n",
            "Epoch [3/10], Loss: 0.5699\n",
            "Epoch [4/10], Loss: 0.5566\n",
            "Epoch [5/10], Loss: 0.5290\n",
            "Epoch [6/10], Loss: 0.4693\n",
            "Epoch [7/10], Loss: 0.4342\n",
            "Epoch [8/10], Loss: 0.4111\n",
            "Epoch [9/10], Loss: 0.3975\n",
            "Epoch [10/10], Loss: 0.3706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using Pretrained Network and finetuning it on the same dataset by removing the prediction head."
      ],
      "metadata": {
        "id": "fkhbzOSKoyNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerClassifier(nn.Module):\n",
        "    def __init__(self, pretrained_model, num_classes=3):\n",
        "        super(VisionTransformerClassifier, self).__init__()\n",
        "        self.encoder = pretrained_model.encoder  # Use the pretrained encoder\n",
        "        self.patch_embedding = pretrained_model.patch_embedding\n",
        "        self.pos_embedding = pretrained_model.pos_embedding\n",
        "        self.cls_token = pretrained_model.cls_token\n",
        "        self.dropout = pretrained_model.dropout\n",
        "\n",
        "        # Classification head\n",
        "        embed_dim = pretrained_model.cls_token.shape[-1]\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Patch embedding and CLS token\n",
        "        x = self.patch_embedding(x)\n",
        "        batch_size = x.shape[0]\n",
        "\n",
        "        # Use self.cls_token instead of pretrained_model.cls_token\n",
        "        cls_tokens = self.cls_token.expand(batch_size, -1, -1)\n",
        "\n",
        "        # Concatenate CLS token and patch tokens\n",
        "        x = torch.cat((cls_tokens, x), dim=1)\n",
        "\n",
        "        # Add positional embeddings and dropout\n",
        "        x += self.pos_embedding\n",
        "        x = self.dropout(x)\n",
        "\n",
        "        # Pass through transformer encoder\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "\n",
        "        # CLS token for classification\n",
        "        cls_token = x[:, 0]  # Use CLS token\n",
        "        x = self.mlp_head(cls_token)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "9Rr_NDVEnABL"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the finetuning model using the pretrained model\n",
        "finetune_model = VisionTransformerClassifier(pretrained_model=MAEInfoNCE_model, num_classes=3).to(device)\n",
        "\n",
        "# Define optimizer and loss function\n",
        "optimizer = optim.Adam(finetune_model.parameters(), lr=0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Fine-tuning loop\n",
        "num_finetune_epochs = 10\n",
        "\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    finetune_model.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for images, labels in train_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = finetune_model(images)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_finetune_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pY6qimORllYJ",
        "outputId": "8b6f1aab-0e4b-4912-e14c-3d0d19111bf1"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.2422\n",
            "Epoch [2/10], Loss: 0.1536\n",
            "Epoch [3/10], Loss: 0.0771\n",
            "Epoch [4/10], Loss: 0.0941\n",
            "Epoch [5/10], Loss: 0.0780\n",
            "Epoch [6/10], Loss: 0.0430\n",
            "Epoch [7/10], Loss: 0.0424\n",
            "Epoch [8/10], Loss: 0.0417\n",
            "Epoch [9/10], Loss: 0.0911\n",
            "Epoch [10/10], Loss: 0.0863\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1c Accuracy and Confusion Matrix\n",
        "Test Accuracy and Confusion Matrix"
      ],
      "metadata": {
        "id": "iB1XXPRUpMtv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation on test data\n",
        "finetune_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = finetune_model(images)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute accuracy\n",
        "accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=selected_classes, yticklabels=selected_classes)\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "sCyFTjLXlmhM",
        "outputId": "f181c9bb-859a-4740-80f9-1bfdadd86497"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 97.67%\n",
            "Confusion Matrix:\n",
            "[[99  0  1]\n",
            " [ 0 99  1]\n",
            " [ 5  0 95]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fdpBhXj3n8K8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1d\n"
      ],
      "metadata": {
        "id": "mhvxutFY-d4A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class VideoPatchEmbedding(nn.Module):\n",
        "    def __init__(self, img_size=28, patch_size=7, in_channels=1, embed_dim=128):\n",
        "        super(VideoPatchEmbedding, self).__init__()\n",
        "        self.patch_size = patch_size\n",
        "        self.embed_dim = embed_dim\n",
        "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
        "\n",
        "    def forward(self, frames):\n",
        "        # frames: (batch_size, num_frames, in_channels, height, width)\n",
        "        batch_size, num_frames, in_channels, height, width = frames.shape\n",
        "\n",
        "        # Apply Conv2d to each frame independently and reshape the patches\n",
        "        patches = []\n",
        "        for t in range(num_frames):\n",
        "            patch_embeddings = self.proj(frames[:, t])  # Shape: (batch_size, embed_dim, num_patches_h, num_patches_w)\n",
        "            patches.append(rearrange(patch_embeddings, 'b e h w -> b (h w) e'))  # Shape: (batch_size, num_patches, embed_dim)\n",
        "\n",
        "        # Concatenate tokens from all frames\n",
        "        patches = torch.cat(patches, dim=1)  # Shape: (batch_size, num_patches * num_frames, embed_dim)\n",
        "        return patches\n"
      ],
      "metadata": {
        "id": "mOzeOiqB-iEm"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, num_patches, embed_dim, num_frames):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.pos_embedding = nn.Parameter(torch.randn(1, num_patches * num_frames, embed_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x: (batch_size, num_patches * num_frames, embed_dim)\n",
        "        return x + self.pos_embedding\n"
      ],
      "metadata": {
        "id": "RJyV0wxrAsxi"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "def shuffle_and_mask(tokens, mask_ratio=0.85):\n",
        "    # tokens: (batch_size, num_tokens, embed_dim)\n",
        "    batch_size, num_tokens, embed_dim = tokens.shape\n",
        "    num_masked = int(num_tokens * mask_ratio)\n",
        "\n",
        "    # Shuffle token indices\n",
        "    shuffled_indices = torch.randperm(num_tokens)\n",
        "\n",
        "    # Separate masked and unmasked tokens\n",
        "    unmasked_indices = shuffled_indices[:num_tokens - num_masked]\n",
        "    masked_indices = shuffled_indices[num_tokens - num_masked:]\n",
        "\n",
        "    unmasked_tokens = tokens[:, unmasked_indices]\n",
        "\n",
        "    # Masked tokens will be appended later during decoding\n",
        "    return unmasked_tokens, masked_indices, unmasked_indices\n"
      ],
      "metadata": {
        "id": "_3WOXe6wAvKC"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VisionTransformerEncoder(nn.Module):\n",
        "    def __init__(self, embed_dim, depth=2, num_heads=8, mlp_dim=256, dropout=0.1):\n",
        "        super(VisionTransformerEncoder, self).__init__()\n",
        "        self.encoder = nn.ModuleList([\n",
        "            TransformerEncoderBlock(embed_dim, num_heads, mlp_dim, dropout)\n",
        "            for _ in range(depth)\n",
        "        ])\n",
        "\n",
        "    def forward(self, x):\n",
        "        for encoder_block in self.encoder:\n",
        "            x = encoder_block(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "xx0mKPi1A2Ee"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoMAEDecoder(nn.Module):\n",
        "    def __init__(self, embed_dim):\n",
        "        super(VideoMAEDecoder, self).__init__()\n",
        "        self.decoder = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "    def forward(self, encoded_tokens, masked_indices, unmasked_indices, batch_size, num_tokens):\n",
        "        # Create a placeholder for all tokens\n",
        "        all_tokens = torch.zeros(batch_size, num_tokens, encoded_tokens.shape[-1]).to(encoded_tokens.device)\n",
        "\n",
        "        # Fill the unmasked tokens in their original positions\n",
        "        all_tokens[:, unmasked_indices] = encoded_tokens\n",
        "\n",
        "        # Decode the masked tokens\n",
        "        all_tokens = self.decoder(all_tokens)\n",
        "        return all_tokens\n"
      ],
      "metadata": {
        "id": "t6U0hyI5A-vj"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def video_mae_loss(reconstructed_tokens, original_tokens):\n",
        "    # L1 loss between reconstructed tokens and original tokens\n",
        "    loss_fn = nn.L1Loss()\n",
        "    return loss_fn(reconstructed_tokens, original_tokens)\n"
      ],
      "metadata": {
        "id": "rfdkpNarBA7U"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the models\n",
        "embed_dim = 128\n",
        "num_patches = 4 * 4  # Assuming each frame is divided into 4x4 patches\n",
        "num_frames = 3\n",
        "\n",
        "patch_embedding = VideoPatchEmbedding(img_size=28, patch_size=7, embed_dim=embed_dim).to(device)\n",
        "positional_encoding = PositionalEncoding(num_patches, embed_dim, num_frames).to(device)\n",
        "encoder = VisionTransformerEncoder(embed_dim).to(device)\n",
        "decoder = VideoMAEDecoder(embed_dim).to(device)\n",
        "\n",
        "optimizer = torch.optim.Adam(list(patch_embedding.parameters()) +\n",
        "                             list(positional_encoding.parameters()) +\n",
        "                             list(encoder.parameters()) +\n",
        "                             list(decoder.parameters()), lr=0.001)\n",
        "\n",
        "num_epochs = 10\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    patch_embedding.train()\n",
        "    total_loss = 0\n",
        "\n",
        "    for video_frames, _ in train_loader:\n",
        "        video_frames = video_frames.to(device)\n",
        "        # Assuming `video_frames` is a 4D tensor (batch_size, in_channels, height, width)\n",
        "\n",
        "        # Simulating video frames by repeating the same frame 3 times (for example)\n",
        "        num_frames = 3\n",
        "        video_frames = video_frames.unsqueeze(1).repeat(1, num_frames, 1, 1, 1)  # Shape: (batch_size, num_frames, in_channels, height, width)\n",
        "\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Step 1: Obtain tokens from video frames\n",
        "        tokens = patch_embedding(video_frames)\n",
        "\n",
        "        # Step 2: Add positional encoding\n",
        "        tokens = positional_encoding(tokens)\n",
        "\n",
        "        # Step 3: Shuffle and mask tokens\n",
        "        unmasked_tokens, masked_indices, unmasked_indices = shuffle_and_mask(tokens, mask_ratio=0.85)\n",
        "\n",
        "        # Step 4: Feed unmasked tokens into the encoder\n",
        "        encoded_tokens = encoder(unmasked_tokens)\n",
        "\n",
        "        # Step 5: Inverse shuffle and append masked tokens, then decode\n",
        "        reconstructed_tokens = decoder(encoded_tokens, masked_indices, unmasked_indices, video_frames.size(0), tokens.size(1))\n",
        "\n",
        "        # Step 6: Compute L1 loss for MAE\n",
        "        loss = video_mae_loss(reconstructed_tokens, tokens)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UY8ymVGZBElF",
        "outputId": "098b4d02-4b33-4c29-ec1d-ef04e3c3e468"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 0.8400\n",
            "Epoch [2/10], Loss: 0.7333\n",
            "Epoch [3/10], Loss: 0.6843\n",
            "Epoch [4/10], Loss: 0.6514\n",
            "Epoch [5/10], Loss: 0.6247\n",
            "Epoch [6/10], Loss: 0.6034\n",
            "Epoch [7/10], Loss: 0.5815\n",
            "Epoch [8/10], Loss: 0.5637\n",
            "Epoch [9/10], Loss: 0.5456\n",
            "Epoch [10/10], Loss: 0.5281\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finetunning"
      ],
      "metadata": {
        "id": "oC3oOObKFLQ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class VideoMAEClassifier(nn.Module):\n",
        "    def __init__(self, patch_embedding, positional_encoding, encoder, num_classes=3):\n",
        "        super(VideoMAEClassifier, self).__init__()\n",
        "\n",
        "        # Use the pretrained patch embedding, positional encoding, and encoder\n",
        "        self.patch_embedding = patch_embedding\n",
        "        self.positional_encoding = positional_encoding\n",
        "        self.encoder = encoder\n",
        "\n",
        "        # Classification head (after mean pooling the tokens)\n",
        "        embed_dim = patch_embedding.proj.out_channels  # Same as the output of the patch embedding\n",
        "        self.mlp_head = nn.Sequential(\n",
        "            nn.LayerNorm(embed_dim),\n",
        "            nn.Linear(embed_dim, num_classes)  # Output: number of classes\n",
        "        )\n",
        "\n",
        "    def forward(self, frames):\n",
        "        # Tokenize the input video frames\n",
        "        tokens = self.patch_embedding(frames)\n",
        "\n",
        "        # Add positional encoding\n",
        "        tokens = self.positional_encoding(tokens)\n",
        "\n",
        "        # Feed to the encoder (no masking during fine-tuning)\n",
        "        encoded_tokens = self.encoder(tokens)\n",
        "\n",
        "        # Mean Pooling the encoded tokens (get the global representation of the video)\n",
        "        global_rep = encoded_tokens.mean(dim=1)  # Shape: (batch_size, embed_dim)\n",
        "\n",
        "        # Feed the global representation to the classification head\n",
        "        logits = self.mlp_head(global_rep)\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "XbXAS1KNL9oj"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reuse the components from the pretraining step\n",
        "patch_embedding = patch_embedding  # Reuse the patch embedding from pretraining\n",
        "positional_encoding = positional_encoding  # Reuse the positional encoding from pretraining\n",
        "encoder = encoder  # Reuse the pretrained encoder from pretraining\n",
        "\n",
        "# Initialize the fine-tuning model with the pretrained components\n",
        "num_classes = 3  # Adjust this to match your number of classes\n",
        "finetune_model = VideoMAEClassifier(patch_embedding, positional_encoding, encoder, num_classes=num_classes).to(device)\n",
        "\n",
        "# Define loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(finetune_model.parameters(), lr=0.001)  # Train all parameters\n",
        "\n",
        "# Fine-tuning loop\n",
        "num_finetune_epochs = 10\n",
        "\n",
        "for epoch in range(num_finetune_epochs):\n",
        "    finetune_model.train()  # Set the model to training mode\n",
        "    total_loss = 0\n",
        "\n",
        "    for video_frames, labels in train_loader:\n",
        "        video_frames = video_frames.to(device)\n",
        "        num_frames = 3\n",
        "        video_frames = video_frames.unsqueeze(1).repeat(1, num_frames, 1, 1, 1)\n",
        "\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = finetune_model(video_frames)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch + 1}/{num_finetune_epochs}], Loss: {avg_loss:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tq0FvZFIFQk5",
        "outputId": "c0fbd0b7-f50d-4388-e65a-db662cee765a"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Loss: 1.3793\n",
            "Epoch [2/10], Loss: 1.0230\n",
            "Epoch [3/10], Loss: 0.7025\n",
            "Epoch [4/10], Loss: 0.4331\n",
            "Epoch [5/10], Loss: 0.2370\n",
            "Epoch [6/10], Loss: 0.1990\n",
            "Epoch [7/10], Loss: 0.1607\n",
            "Epoch [8/10], Loss: 0.0793\n",
            "Epoch [9/10], Loss: 0.0521\n",
            "Epoch [10/10], Loss: 0.0530\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing and accuracy calculation\n",
        "finetune_model.eval()  # Set the model to evaluation mode\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation for testing\n",
        "    for video_frames, labels in test_loader:\n",
        "        video_frames = video_frames.to(device)\n",
        "        num_frames = 3\n",
        "        video_frames = video_frames.unsqueeze(1).repeat(1, num_frames, 1, 1, 1)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = finetune_model(video_frames)\n",
        "\n",
        "        # Get predictions\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        # Collect predictions and labels\n",
        "        all_preds.extend(preds.cpu().numpy())\n",
        "        all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "# Compute test accuracy\n",
        "test_accuracy = accuracy_score(all_labels, all_preds)\n",
        "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
        "\n",
        "# Compute confusion matrix\n",
        "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix)\n",
        "\n",
        "# Plot confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 651
        },
        "id": "oZgZ4gMPHN0G",
        "outputId": "9f78d32d-ebe0-42c4-bf48-319bef0a6b85"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 96.33%\n",
            "Confusion Matrix:\n",
            "[[100   0   0]\n",
            " [  1  96   3]\n",
            " [  7   0  93]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 800x600 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cdhFxIyyMcm0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}